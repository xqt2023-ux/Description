# è¯´è¯äººè¯†åˆ«ä¸å¤´åƒæ˜¾ç¤º - æŠ€æœ¯è§„èŒƒæ–‡æ¡£

> **åŠŸèƒ½ç¼–å·**: SD-001  
> **åˆ›å»ºæ—¥æœŸ**: 2026-02-09  
> **çŠ¶æ€**: å¾…å¼€å‘  
> **é¢„è®¡å·¥æ—¶**: 5-6å°æ—¶

---

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

ä¸ºè§†é¢‘è½¬å½•åŠŸèƒ½æ·»åŠ è¯´è¯äººè¯†åˆ«ï¼ˆSpeaker Diarizationï¼‰å’Œå¤´åƒæ˜¾ç¤ºåŠŸèƒ½ï¼Œå¸®åŠ©ç”¨æˆ·åŒºåˆ†ä¸åŒè¯´è¯äººã€‚

### æ ¸å¿ƒç‰¹æ€§

1. âœ… **AIè‡ªåŠ¨è¯†åˆ«** - ä½¿ç”¨pyannote.audioè‡ªåŠ¨è¯†åˆ«ä¸åŒè¯´è¯äºº
2. âœ… **æ··åˆæ¨¡å¼** - AIè¯†åˆ«ç»“æœå¯ç”±ç”¨æˆ·æ‰‹åŠ¨è°ƒæ•´
3. âœ… **å¤´åƒæå–** - è‡ªåŠ¨ä»è§†é¢‘ä¸­æå–æ¯ä¸ªè¯´è¯äººçš„ç¬¬ä¸€å¸§ä½œä¸ºå¤´åƒ
4. âœ… **é‡å‘½åæ”¯æŒ** - ç”¨æˆ·å¯å°†"è¯´è¯äºº1"é‡å‘½åä¸º"Alice"ç­‰
5. âœ… **æ™ºèƒ½æ˜¾ç¤º** - åªåœ¨è¯´è¯äººåˆ‡æ¢æ—¶æ˜¾ç¤ºå¤´åƒï¼ŒèŠ‚çœç©ºé—´

---

## ğŸ¯ ç”¨æˆ·æ•…äº‹

**ä½œä¸ºè§†é¢‘ç¼–è¾‘ç”¨æˆ·**
- æˆ‘å¸Œæœ›ç³»ç»Ÿèƒ½è‡ªåŠ¨è¯†åˆ«è§†é¢‘ä¸­ä¸åŒçš„è¯´è¯äºº
- æˆ‘å¸Œæœ›çœ‹åˆ°æ¯ä¸ªè¯´è¯äººçš„å¤´åƒ
- æˆ‘å¸Œæœ›èƒ½ç»™è¯´è¯äººè®¾ç½®æœ‰æ„ä¹‰çš„åå­—
- æˆ‘å¸Œæœ›UIç®€æ´ï¼Œä¸é‡å¤æ˜¾ç¤ºç›¸åŒè¯´è¯äººçš„å¤´åƒ

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æŠ€æœ¯æ ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Frontend (Next.js)             â”‚
â”‚  - SpeakerAvatar.tsx                    â”‚
â”‚  - SpeakerHeader.tsx                    â”‚
â”‚  - TranscriptEditor.tsx (æ›´æ–°)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Backend (Node.js/Express)         â”‚
â”‚  - speakerDiarization.ts                â”‚
â”‚  - frameExtraction.ts                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Python Service (Flask)             â”‚
â”‚  - pyannote.audio                       â”‚
â”‚  - diarization_service.py               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµ

```
1. ç”¨æˆ·ä¸Šä¼ è§†é¢‘
   â†“
2. æå–éŸ³é¢‘ (FFmpeg)
   â†“
3. è¯­éŸ³è½¬æ–‡æœ¬ (Whisper)
   â†“
4. è¯´è¯äººè¯†åˆ« (pyannote.audio) â† æ–°å¢
   â†“
5. æå–å¤´åƒå¸§ (FFmpeg) â† æ–°å¢
   â†“
6. å­˜å‚¨åˆ°Transcript
   â†“
7. å‰ç«¯æ¸²æŸ“æ˜¾ç¤º
```

---

## ğŸ“Š æ•°æ®ç»“æ„è®¾è®¡

### 1. Speakerç±»å‹å®šä¹‰

```typescript
// shared/types/index.ts

export interface Speaker {
  id: string;                    // "speaker-uuid"
  label: string;                 // "SPEAKER_00", "SPEAKER_01"
  customName?: string;           // "Alice", "Bob" (ç”¨æˆ·å¯ç¼–è¾‘)
  color?: string;                // å¤´åƒè¾¹æ¡†é¢œè‰² "#FF6B6B"
  avatarPath?: string;           // "/uploads/avatars/xxx.jpg"
  avatarUrl?: string;            // å®Œæ•´URL
  firstAppearance: number;       // é¦–æ¬¡å‡ºç°æ—¶é—´æˆ³ (ç§’)
  totalDuration: number;         // æ€»è¯´è¯æ—¶é•¿ (ç§’)
  segmentCount: number;          // è¯´è¯ç‰‡æ®µæ•°é‡
}
```

### 2. æ‰©å±•TranscriptSegment

```typescript
export interface TranscriptSegment {
  id: string;
  text: string;
  startTime: number;
  endTime: number;
  words: Word[];
  
  // æ–°å¢å­—æ®µ
  speakerId?: string;            // å¯¹åº”Speaker.id
  confidence?: number;           // è¯†åˆ«ç½®ä¿¡åº¦ 0-1
}
```

### 3. æ‰©å±•Transcript

```typescript
export interface Transcript {
  id: string;
  mediaId: string;
  language: string;
  segments: TranscriptSegment[];
  createdAt: string;
  updatedAt: string;
  
  // æ–°å¢å­—æ®µ
  speakers?: Speaker[];          // è¯´è¯äººåˆ—è¡¨
  diarizationStatus?: 'pending' | 'processing' | 'completed' | 'failed';
  diarizationError?: string;
}
```

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### Phase 1: PythonæœåŠ¡æ­å»º

#### 1.1 ç¯å¢ƒå‡†å¤‡

```bash
# backend/python/setup.sh
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install pyannote.audio torch torchaudio flask
```

#### 1.2 requirements.txt

```txt
pyannote.audio==3.1.1
torch>=2.0.0
torchaudio>=2.0.0
flask==3.0.0
python-dotenv==1.0.0
```

#### 1.3 è¯´è¯äººè¯†åˆ«æœåŠ¡

```python
# backend/python/diarization_service.py

from flask import Flask, request, jsonify
from pyannote.audio import Pipeline
import os

app = Flask(__name__)

# åŠ è½½æ¨¡å‹ (éœ€è¦HuggingFace token)
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-3.1",
    use_auth_token=os.getenv("HUGGINGFACE_TOKEN")
)

@app.route('/diarize', methods=['POST'])
def diarize():
    """
    è¯´è¯äººè¯†åˆ«æ¥å£
    è¾“å…¥: { "audio_path": "/path/to/audio.wav" }
    è¾“å‡º: { "segments": [...], "speakers": [...] }
    """
    try:
        audio_path = request.json['audio_path']
        
        # æ‰§è¡Œè¯´è¯äººè¯†åˆ«
        diarization = pipeline(audio_path)
        
        # è§£æç»“æœ
        segments = []
        speakers = set()
        
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                "start": turn.start,
                "end": turn.end,
                "speaker": speaker
            })
            speakers.add(speaker)
        
        return jsonify({
            "success": True,
            "segments": segments,
            "speakers": list(speakers)
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

#### 1.4 å¯åŠ¨è„šæœ¬

```bash
# backend/python/start.sh
#!/bin/bash
source venv/bin/activate
python diarization_service.py
```

---

### Phase 2: Node.jsåç«¯é›†æˆ

#### 2.1 è°ƒç”¨PythonæœåŠ¡

```typescript
// backend/src/services/speakerDiarization.ts

import axios from 'axios';

const PYTHON_SERVICE_URL = process.env.PYTHON_SERVICE_URL || 'http://localhost:5000';

export interface DiarizationSegment {
  start: number;
  end: number;
  speaker: string;
}

export interface DiarizationResult {
  segments: DiarizationSegment[];
  speakers: string[];
}

/**
 * è°ƒç”¨PythonæœåŠ¡è¿›è¡Œè¯´è¯äººè¯†åˆ«
 */
export async function performSpeakerDiarization(
  audioPath: string
): Promise<DiarizationResult> {
  try {
    const response = await axios.post(`${PYTHON_SERVICE_URL}/diarize`, {
      audio_path: audioPath
    }, {
      timeout: 300000, // 5åˆ†é’Ÿè¶…æ—¶
    });

    if (!response.data.success) {
      throw new Error(response.data.error || 'Diarization failed');
    }

    return {
      segments: response.data.segments,
      speakers: response.data.speakers
    };
  } catch (error: any) {
    console.error('Speaker diarization error:', error);
    throw new Error(`Failed to perform speaker diarization: ${error.message}`);
  }
}

/**
 * å°†è¯´è¯äººè¯†åˆ«ç»“æœæ˜ å°„åˆ°è½¬å½•ç‰‡æ®µ
 */
export function mapSpeakersToTranscript(
  transcriptSegments: TranscriptSegment[],
  diarizationSegments: DiarizationSegment[]
): TranscriptSegment[] {
  return transcriptSegments.map(segment => {
    // æ‰¾åˆ°ä¸è¯¥è½¬å½•ç‰‡æ®µé‡å æœ€å¤šçš„è¯´è¯äººç‰‡æ®µ
    const overlappingSpeaker = findOverlappingSpeaker(
      segment.startTime,
      segment.endTime,
      diarizationSegments
    );

    return {
      ...segment,
      speakerId: overlappingSpeaker?.speaker,
      confidence: calculateConfidence(segment, overlappingSpeaker)
    };
  });
}

function findOverlappingSpeaker(
  start: number,
  end: number,
  diarizationSegments: DiarizationSegment[]
): DiarizationSegment | null {
  let maxOverlap = 0;
  let bestMatch: DiarizationSegment | null = null;

  for (const diaSeg of diarizationSegments) {
    const overlapStart = Math.max(start, diaSeg.start);
    const overlapEnd = Math.min(end, diaSeg.end);
    const overlap = Math.max(0, overlapEnd - overlapStart);

    if (overlap > maxOverlap) {
      maxOverlap = overlap;
      bestMatch = diaSeg;
    }
  }

  return bestMatch;
}

function calculateConfidence(
  segment: TranscriptSegment,
  diarizationSegment: DiarizationSegment | null
): number {
  if (!diarizationSegment) return 0;

  const segmentDuration = segment.endTime - segment.startTime;
  const overlapStart = Math.max(segment.startTime, diarizationSegment.start);
  const overlapEnd = Math.min(segment.endTime, diarizationSegment.end);
  const overlap = Math.max(0, overlapEnd - overlapStart);

  return overlap / segmentDuration;
}
```

#### 2.2 è§†é¢‘å¸§æå–

```typescript
// backend/src/services/frameExtraction.ts

import ffmpeg from 'fluent-ffmpeg';
import path from 'path';
import fs from 'fs';
import { v4 as uuidv4 } from 'uuid';

/**
 * ä»è§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´æˆ³çš„å¸§
 */
export async function extractFrameAtTime(
  videoPath: string,
  timestamp: number,
  outputDir: string = path.join(__dirname, '../../uploads/avatars')
): Promise<string> {
  // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  const outputPath = path.join(outputDir, `${uuidv4()}.jpg`);

  return new Promise((resolve, reject) => {
    ffmpeg(videoPath)
      .screenshots({
        timestamps: [timestamp],
        filename: path.basename(outputPath),
        folder: outputDir,
        size: '320x240'
      })
      .on('end', () => {
        console.log(`Frame extracted: ${outputPath}`);
        resolve(outputPath);
      })
      .on('error', (err) => {
        console.error('Frame extraction error:', err);
        reject(new Error(`Failed to extract frame: ${err.message}`));
      });
  });
}

/**
 * ä¸ºæ‰€æœ‰è¯´è¯äººæå–å¤´åƒ
 */
export async function extractSpeakerAvatars(
  videoPath: string,
  speakers: DiarizationSegment[]
): Promise<Map<string, string>> {
  const avatarMap = new Map<string, string>();
  const processedSpeakers = new Set<string>();

  for (const segment of speakers) {
    if (processedSpeakers.has(segment.speaker)) {
      continue; // å·²å¤„ç†è¿‡æ­¤è¯´è¯äºº
    }

    try {
      const avatarPath = await extractFrameAtTime(
        videoPath,
        segment.start + 0.5 // ç¨å¾®å»¶è¿Ÿ0.5ç§’ï¼Œé¿å…é»‘å±
      );
      avatarMap.set(segment.speaker, avatarPath);
      processedSpeakers.add(segment.speaker);
    } catch (error) {
      console.error(`Failed to extract avatar for ${segment.speaker}:`, error);
    }
  }

  return avatarMap;
}
```

#### 2.3 é›†æˆåˆ°è½¬å½•æµç¨‹

```typescript
// backend/src/services/transcription.ts (æ›´æ–°)

import { performSpeakerDiarization, mapSpeakersToTranscript } from './speakerDiarization';
import { extractSpeakerAvatars } from './frameExtraction';

async function processTranscriptionJob(jobId: string): Promise<void> {
  const job = jobStore.get<TranscriptionJobData>(jobId);
  if (!job) return;

  try {
    // ... ç°æœ‰çš„è½¬å½•é€»è¾‘ ...

    jobStore.update(jobId, { progress: 60 });

    // æ–°å¢ï¼šè¯´è¯äººè¯†åˆ«
    if (process.env.ENABLE_SPEAKER_DIARIZATION === 'true') {
      console.log('[Transcription] Performing speaker diarization...');
      
      const diarizationResult = await performSpeakerDiarization(audioPath);
      
      // æ˜ å°„è¯´è¯äººåˆ°è½¬å½•ç‰‡æ®µ
      transcript.segments = mapSpeakersToTranscript(
        transcript.segments,
        diarizationResult.segments
      );

      // æå–å¤´åƒ
      const avatarMap = await extractSpeakerAvatars(
        filePath,
        diarizationResult.segments
      );

      // åˆ›å»ºSpeakerå¯¹è±¡
      transcript.speakers = diarizationResult.speakers.map(speakerLabel => ({
        id: `speaker-${uuidv4()}`,
        label: speakerLabel,
        customName: undefined,
        avatarPath: avatarMap.get(speakerLabel),
        avatarUrl: avatarMap.get(speakerLabel)
          ? `/api/media/avatar/${path.basename(avatarMap.get(speakerLabel)!)}`
          : undefined,
        firstAppearance: findFirstAppearance(diarizationResult.segments, speakerLabel),
        totalDuration: calculateTotalDuration(diarizationResult.segments, speakerLabel),
        segmentCount: countSegments(diarizationResult.segments, speakerLabel),
      }));

      transcript.diarizationStatus = 'completed';
    }

    jobStore.update(jobId, { progress: 90 });

    // ... å…¶ä½™é€»è¾‘ ...
  } catch (error: any) {
    // ... é”™è¯¯å¤„ç† ...
  }
}
```

#### 2.4 æ–°å¢APIè·¯ç”±

```typescript
// backend/src/routes/transcription.ts (æ–°å¢)

/**
 * æ›´æ–°è¯´è¯äººä¿¡æ¯ï¼ˆé‡å‘½åã€æ‰‹åŠ¨è°ƒæ•´ï¼‰
 */
router.put('/transcript/:transcriptId/speakers/:speakerId', async (req, res) => {
  try {
    const { transcriptId, speakerId } = req.params;
    const { customName, color } = req.body;

    // åŠ è½½transcript
    const transcript = await loadTranscript(transcriptId);
    if (!transcript) {
      return res.status(404).json({ error: 'Transcript not found' });
    }

    // æ›´æ–°è¯´è¯äººä¿¡æ¯
    const speaker = transcript.speakers?.find(s => s.id === speakerId);
    if (!speaker) {
      return res.status(404).json({ error: 'Speaker not found' });
    }

    if (customName !== undefined) {
      speaker.customName = customName;
    }
    if (color !== undefined) {
      speaker.color = color;
    }

    // ä¿å­˜
    await saveTranscript(transcript);

    res.json({
      success: true,
      speaker
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * æ‰‹åŠ¨è°ƒæ•´ç‰‡æ®µçš„è¯´è¯äºº
 */
router.put('/transcript/:transcriptId/segment/:segmentId/speaker', async (req, res) => {
  try {
    const { transcriptId, segmentId } = req.params;
    const { speakerId } = req.body;

    const transcript = await loadTranscript(transcriptId);
    if (!transcript) {
      return res.status(404).json({ error: 'Transcript not found' });
    }

    const segment = transcript.segments.find(s => s.id === segmentId);
    if (!segment) {
      return res.status(404).json({ error: 'Segment not found' });
    }

    segment.speakerId = speakerId;
    segment.confidence = 1.0; // æ‰‹åŠ¨è®¾ç½®ï¼Œç½®ä¿¡åº¦ä¸º1

    await saveTranscript(transcript);

    res.json({
      success: true,
      segment
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});
```

---

### Phase 3: å‰ç«¯å®ç°

#### 3.1 SpeakerAvatarç»„ä»¶

```tsx
// frontend/src/components/editor/SpeakerAvatar.tsx

import { Speaker } from '@/types';

interface SpeakerAvatarProps {
  speaker: Speaker;
  size?: 'sm' | 'md' | 'lg';
}

export function SpeakerAvatar({ speaker, size = 'md' }: SpeakerAvatarProps) {
  const sizeClasses = {
    sm: 'w-8 h-8',
    md: 'w-12 h-12',
    lg: 'w-16 h-16',
  };

  const displayName = speaker.customName || speaker.label;
  const initials = displayName.slice(0, 2).toUpperCase();

  return (
    <div 
      className={`${sizeClasses[size]} rounded-full overflow-hidden border-2 flex items-center justify-center`}
      style={{ borderColor: speaker.color || '#6B7280' }}
    >
      {speaker.avatarUrl ? (
        <img
          src={speaker.avatarUrl}
          alt={displayName}
          className="w-full h-full object-cover"
        />
      ) : (
        <div 
          className="w-full h-full flex items-center justify-center text-white font-semibold"
          style={{ backgroundColor: speaker.color || '#6B7280' }}
        >
          {initials}
        </div>
      )}
    </div>
  );
}
```

#### 3.2 SpeakerHeaderç»„ä»¶

```tsx
// frontend/src/components/editor/SpeakerHeader.tsx

import { useState } from 'react';
import { Speaker } from '@/types';
import { SpeakerAvatar } from './SpeakerAvatar';
import { Edit2, Check, X } from 'lucide-react';

interface SpeakerHeaderProps {
  speaker: Speaker;
  onRename: (speakerId: string, newName: string) => void;
}

export function SpeakerHeader({ speaker, onRename }: SpeakerHeaderProps) {
  const [isEditing, setIsEditing] = useState(false);
  const [editName, setEditName] = useState(speaker.customName || speaker.label);

  const handleSave = () => {
    onRename(speaker.id, editName);
    setIsEditing(false);
  };

  const handleCancel = () => {
    setEditName(speaker.customName || speaker.label);
    setIsEditing(false);
  };

  return (
    <div className="flex items-center gap-3 py-2 px-3 bg-gray-50 rounded-lg mb-2">
      <SpeakerAvatar speaker={speaker} size="md" />
      
      <div className="flex-1">
        {isEditing ? (
          <div className="flex items-center gap-2">
            <input
              type="text"
              value={editName}
              onChange={(e) => setEditName(e.target.value)}
              className="flex-1 px-2 py-1 border border-gray-300 rounded text-sm"
              autoFocus
              onKeyDown={(e) => {
                if (e.key === 'Enter') handleSave();
                if (e.key === 'Escape') handleCancel();
              }}
            />
            <button
              onClick={handleSave}
              className="p-1 text-green-600 hover:bg-green-50 rounded"
            >
              <Check className="w-4 h-4" />
            </button>
            <button
              onClick={handleCancel}
              className="p-1 text-gray-600 hover:bg-gray-100 rounded"
            >
              <X className="w-4 h-4" />
            </button>
          </div>
        ) : (
          <div className="flex items-center gap-2">
            <span className="font-medium text-sm">
              {speaker.customName || speaker.label}
            </span>
            <button
              onClick={() => setIsEditing(true)}
              className="p-1 text-gray-400 hover:text-gray-600 hover:bg-gray-100 rounded"
            >
              <Edit2 className="w-3 h-3" />
            </button>
          </div>
        )}
        <p className="text-xs text-gray-500">
          {Math.round(speaker.totalDuration)}s Â· {speaker.segmentCount} segments
        </p>
      </div>
    </div>
  );
}
```

#### 3.3 æ›´æ–°TranscriptEditor

```tsx
// frontend/src/components/editor/TranscriptEditor.tsx (æ›´æ–°)

import { SpeakerHeader } from './SpeakerHeader';
import { updateSpeakerName, updateSegmentSpeaker } from '@/lib/api';

export function TranscriptEditor() {
  const { transcript, updateTranscript } = useEditorStore();

  const handleRenameSpeaker = async (speakerId: string, newName: string) => {
    try {
      await updateSpeakerName(transcript.id, speakerId, newName);
      // æ›´æ–°æœ¬åœ°çŠ¶æ€
      updateTranscript({
        speakers: transcript.speakers?.map(s => 
          s.id === speakerId ? { ...s, customName: newName } : s
        )
      });
    } catch (error) {
      console.error('Failed to rename speaker:', error);
    }
  };

  const getSpeaker = (speakerId?: string) => {
    return transcript.speakers?.find(s => s.id === speakerId);
  };

  return (
    <div className="space-y-2">
      {transcript.segments.map((segment, index) => {
        const prevSegment = index > 0 ? transcript.segments[index - 1] : null;
        const showSpeaker = segment.speakerId && 
          segment.speakerId !== prevSegment?.speakerId;
        
        const speaker = getSpeaker(segment.speakerId);

        return (
          <div key={segment.id}>
            {showSpeaker && speaker && (
              <SpeakerHeader
                speaker={speaker}
                onRename={handleRenameSpeaker}
              />
            )}
            
            <div className="pl-3 py-1 text-sm text-gray-700">
              {segment.text}
            </div>
          </div>
        );
      })}
    </div>
  );
}
```

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```typescript
// backend/src/__tests__/speakerDiarization.test.ts

describe('Speaker Diarization', () => {
  test('should map speakers to transcript segments', () => {
    // æµ‹è¯•è¯´è¯äººæ˜ å°„é€»è¾‘
  });

  test('should calculate speaker confidence', () => {
    // æµ‹è¯•ç½®ä¿¡åº¦è®¡ç®—
  });

  test('should extract frame at specific timestamp', () => {
    // æµ‹è¯•è§†é¢‘å¸§æå–
  });
});
```

### é›†æˆæµ‹è¯•

```typescript
// E2Eæµ‹è¯•åœºæ™¯
1. ä¸Šä¼ åŒ…å«2ä¸ªè¯´è¯äººçš„è§†é¢‘
2. ç­‰å¾…è½¬å½•å®Œæˆ
3. éªŒè¯è¯†åˆ«å‡º2ä¸ªè¯´è¯äºº
4. éªŒè¯æ¯ä¸ªè¯´è¯äººéƒ½æœ‰å¤´åƒ
5. é‡å‘½åè¯´è¯äºº
6. æ‰‹åŠ¨è°ƒæ•´æŸæ®µçš„è¯´è¯äºº
7. éªŒè¯UIæ›´æ–°æ­£ç¡®
```

---

## ğŸ“ ç¯å¢ƒé…ç½®

### .envé…ç½®

```bash
# PythonæœåŠ¡
PYTHON_SERVICE_URL=http://localhost:5000
ENABLE_SPEAKER_DIARIZATION=true

# HuggingFace Token (ç”¨äºä¸‹è½½pyannoteæ¨¡å‹)
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxx
```

### å¯åŠ¨é¡ºåº

```bash
# 1. å¯åŠ¨PythonæœåŠ¡
cd backend/python
python diarization_service.py

# 2. å¯åŠ¨Node.jsåç«¯
cd backend
npm run dev

# 3. å¯åŠ¨å‰ç«¯
cd frontend
npm run dev
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹ä¸é™åˆ¶

### æŠ€æœ¯é™åˆ¶

1. **é¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è½½æ¨¡å‹** - çº¦500MBï¼Œéœ€è¦è‰¯å¥½çš„ç½‘ç»œ
2. **å¤„ç†æ—¶é—´** - 5åˆ†é’Ÿè§†é¢‘çº¦éœ€30ç§’-2åˆ†é’Ÿå¤„ç†
3. **å†…å­˜éœ€æ±‚** - å»ºè®®è‡³å°‘4GBå¯ç”¨å†…å­˜
4. **GPUåŠ é€Ÿ** - æ”¯æŒCUDAï¼Œå¯å¤§å¹…æå‡é€Ÿåº¦

### å·²çŸ¥é—®é¢˜

1. **é‡å è¯­éŸ³** - å¤šäººåŒæ—¶è¯´è¯æ—¶è¯†åˆ«å¯èƒ½ä¸å‡†ç¡®
2. **èƒŒæ™¯éŸ³ä¹** - å¼ºèƒŒæ™¯éŸ³ä¹å¯èƒ½å½±å“è¯†åˆ«ç²¾åº¦
3. **ç›¸ä¼¼å£°éŸ³** - éŸ³è‰²ç›¸ä¼¼çš„è¯´è¯äººå¯èƒ½è¢«è¯†åˆ«ä¸ºåŒä¸€äºº

### è§£å†³æ–¹æ¡ˆ

- æä¾›æ‰‹åŠ¨è°ƒæ•´åŠŸèƒ½ï¼ˆæ··åˆæ¨¡å¼ï¼‰
- æ˜¾ç¤ºç½®ä¿¡åº¦ï¼Œè®©ç”¨æˆ·åˆ¤æ–­
- æ”¯æŒåˆå¹¶/åˆ†å‰²è¯´è¯äºº

---

## ğŸ“… å¼€å‘æ’æœŸ

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | è´Ÿè´£äºº |
|------|------|---------|--------|
| Phase 1 | PythonæœåŠ¡æ­å»º | 1å°æ—¶ | Backend |
| Phase 2 | Node.jsé›†æˆ | 2-3å°æ—¶ | Backend |
| Phase 3 | å‰ç«¯å¼€å‘ | 2å°æ—¶ | Frontend |
| Phase 4 | æµ‹è¯•ä¸ä¼˜åŒ– | 1å°æ—¶ | QA |

**æ€»è®¡**: 5-6å°æ—¶

---

## âœ… éªŒæ”¶æ ‡å‡†

1. âœ… èƒ½è‡ªåŠ¨è¯†åˆ«è§†é¢‘ä¸­çš„ä¸åŒè¯´è¯äºº
2. âœ… æ¯ä¸ªè¯´è¯äººæ˜¾ç¤ºå¤´åƒï¼ˆä»è§†é¢‘æå–ï¼‰
3. âœ… åªåœ¨è¯´è¯äººåˆ‡æ¢æ—¶æ˜¾ç¤ºå¤´åƒ
4. âœ… ç”¨æˆ·å¯ä»¥é‡å‘½åè¯´è¯äºº
5. âœ… ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è°ƒæ•´ç‰‡æ®µçš„è¯´è¯äººå½’å±
6. âœ… è¯†åˆ«å‡†ç¡®ç‡ > 80%ï¼ˆæ­£å¸¸å¯¹è¯åœºæ™¯ï¼‰
7. âœ… 5åˆ†é’Ÿè§†é¢‘å¤„ç†æ—¶é—´ < 3åˆ†é’Ÿ

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [pyannote.audioæ–‡æ¡£](https://github.com/pyannote/pyannote-audio)
- [Speaker Diarizationè®ºæ–‡](https://arxiv.org/abs/2012.01477)
- [FFmpegæ–‡æ¡£](https://ffmpeg.org/documentation.html)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026-02-09  
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
